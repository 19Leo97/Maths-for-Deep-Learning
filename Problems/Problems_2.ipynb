{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOnRi9prPGEK6J4W062dro5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Problems Chapter 2**\n","## **Problem 2.1**\n","To walk “downhill” on the loss function (equation 2.5), we measure its gradient with respect to the parameters $\\phi_0$ and $\\phi_1$. Calculate expressions for the slopes $\\frac{\\partial L}{\\partial \\phi_0}$ and $\\frac{\\partial L}{\\partial \\phi_1}$.\n","###**Answer**\n","Let's remember the loss function (equation 2.5):\n","\\begin{align}\n","  L[\\phi] = \\sum_{i=1}^{I} (\\phi_0 + \\phi_1 x_i - y_i)^2\n","\\end{align}\n","Then, we have by sum and chain rules:\n","\\begin{align}\n","  \\frac{\\partial L}{\\partial \\phi_0} = \\sum_{i=1}^{I} 2 (\\phi_0 + \\phi_1 x_i - y_i) \\tag{1}\\\\\n","  \\frac{\\partial L}{\\partial \\phi_1} = \\sum_{i=1}^{I} 2 (\\phi_0 + \\phi_1 x_i - y_i)x_i \\tag{2}\n","\\end{align}\n","\n","##**Problem 2.2**\n","Show that we can find the minimum of the loss function in closed form by setting\n","the expression for the derivatives from problem 2.1 to zero and solving for $\\phi_0$ and $\\phi_1$. Note that this works for linear regression but not for more complex models; this is why we use iterative model fitting methods like gradient descent (figure 2.4).\n","###**Aswer**\n","Let's take equation (1) and equal it to 0, then find the value for $\\phi_0$:\n","\\begin{align}\n","  0 = \\sum_{i=1}^{I} 2 (\\phi_0 + \\phi_1 x_i - y_i)\\\\\n","  0 = 2\\sum_{i=1}^{I} \\phi_0 + 2\\sum_{i=1}^{I}(\\phi_1 x_i - y_i)\\\\\n","  0 = 2I \\phi_0 + 2\\sum_{i=1}^{I}(\\phi_1 x_i - y_i)\\\\\n","  \\phi_0 = - \\frac{\\sum_{i=1}^{I}(\\phi_1 x_i - y_i)}{I} \\tag{3}\n","\\end{align}\n","Now, let's take equation (2), equal it to 0, then replace the value of $\\phi_0$:\n","\\begin{align}\n","  0 = \\sum_{i=1}^{I} 2 (\\phi_0 + \\phi_1 x_i - y_i)x_i\\\\\n","  0 = \\phi_0 \\sum_{i=1}^{I} x_i + \\sum_{i=1}^{I} (\\phi_1 x_i - y_i)x_i\\\\\n","  0 = \\left(- \\frac{\\sum_{i=1}^{I}(\\phi_1 x_i - y_i)}{I}\\right) \\sum_{i=1}^{I} x_i + \\sum_{i=1}^{I} (\\phi_1 x_i - y_i)x_i\\\\\n","  0 = -I^{-1} \\left(\\sum_{i=1}^{I} \\phi_1 x_i - \\sum_{i=1}^{I} y_i \\right)\\sum_{i=1}^{I} x_i + \\sum_{i=1}^{I} \\phi_1 x_i^2 - \\sum_{i=1}^{I} x_i y_i\\\\\n","0 = I^{-1} \\phi_1 \\sum_{i=1}^{I} x_i \\sum_{i=1}^{I} x_i - \\sum_{i=1}^{I} y_i \\sum_{i=1}^{I} x_i + \\phi_1 \\sum_{i=1}^{I} x_i^2 - \\sum_{i=1}^{I} x_i y_i\\\\\n","0 = \\phi_1 \\left( -I^{-1} \\left(\\sum_{i=1}^{I}x_i\\right)^2 + \\sum_{i=1}^{I} x_i^2  \\right) - \\sum_{i=1}^{I}y_i \\sum_{i=1}^{I} x_i - \\sum_{i=1}^{I} x_i y_i\\\\\n","\\phi_1 =  \\frac{\\sum_{i=1}^{I}y_i \\sum_{i=1}^{I} x_i + \\sum_{i=1}^{I} x_i y_i}{ -I^{-1} \\left(\\sum_{i=1}^{I}x_i\\right)^2 + \\sum_{i=1}^{I} x_i^2 } \\tag{4}\n","\\end{align}\n","Now we can get the value of $\\phi_0$ replacing this value of $\\phi_1$ we just got in (3).\n","\n","##**Problem 2.3**\n","Consider reformulating linear regression as a generative model, so we have $x =\n","g[y, \\phi] = \\phi_0 + \\phi_1y$. What is the new loss function? Find an expression for the inverse function $y = g^{−1}[x, \\phi]$ that we would use to perform inference. Will this model make the same predictions as the discriminative version for a given training dataset ${xi, yi}$? One way to\n","establish this is to write code that fits a line to three data points using both methods and see if the result is the same.\n","###**Answer**\n","We can get the inverse of $g[y, \\phi]$, it is $g^{−1}[x, \\phi] = y = \\frac{x - \\phi_0}{\\phi_1}$.\n","\n","The new loss function will be:\n","\\begin{align}\n","  L[\\phi] = \\sum_{i=1}^{I} (g^{−1}[x_i, \\phi] - y_i)^2\\\\\n","  L[\\phi] = \\sum_{i=1}^{I} ( \\frac{x_i - \\phi_0}{\\phi_1} - y_i)^2\n","\\end{align}\n","If we take $\\phi_0' = -\\frac{\\phi_0}{\\phi_1}$ and $\\phi_1' = \\frac{1}{\\phi_1}$, we will obtain the standard linear regression model. Therefore, we will end up with the same predictions but with different parameter values.\n","\n","\n"],"metadata":{"id":"w-jrd9gRd9Te"}}]}